# üõ°Ô∏è Detec√ß√£o de Fraude em Cart√µes de Cr√©dito com Machine Learning

Este projeto apresenta uma abordagem de machine learning para identificar transa√ß√µes potencialmente fraudulentas em um grande conjunto de dados de cart√µes de cr√©dito. O objetivo √© desenvolver um modelo eficiente, confi√°vel e interpret√°vel para apoiar decis√µes em ambientes de risco financeiro.

---

## üìÇ Sum√°rio

- [Contexto do Problema](#contexto-do-problema)
- [Objetivos do Projeto](#objetivos-do-projeto)
- [Descri√ß√£o dos Dados](#descri√ß√£o-dos-dados)
- [An√°lise explorat√≥ria de dados](#analise-exploratoria-de-dados)
---

## üìå Contexto do Problema

Fraudes com cart√µes de cr√©dito causam bilh√µes em preju√≠zo √†s institui√ß√µes financeiras anualmente. A maioria dos sistemas de detec√ß√£o tradicionais apresenta dificuldades em:
- Adaptar-se a padr√µes de fraude em constante mudan√ßa
- Lidar com dados extremamente desbalanceados
- Minimizar falsos positivos sem deixar fraudes passarem despercebidas

---

## üéØ Objetivos do Projeto

- Desenvolver um modelo de classifica√ß√£o bin√°ria para prever fraudes em transa√ß√µes de cart√£o de cr√©dito
- Avaliar a performance com m√©tricas adequadas a datasets desbalanceados
- Demonstrar um pipeline completo de machine learning com boas pr√°ticas de engenharia de dados e valida√ß√£o

---

## üßæ Descri√ß√£o dos Dados

- **Fonte**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Tipos de dados**: 30 float64 e 1 int64
- **Total de transa√ß√µes**: 284.807 (sem dados ausentes)
- **Transa√ß√µes fraudulentas**: 492 (aproximadamente 0,172%)
- **Colunas principais**:
  - `V1` a `V28`: vari√°veis transformadas via PCA para anonimiza√ß√£o
  - `Amount`: valor da transa√ß√£o
  - `Time`: segundos desde a primeira transa√ß√£o no dataset
  - `Class`: vari√°vel alvo (0 = leg√≠tima, 1 = fraude)

---
## üìä An√°lise explorat√≥ria de dados

### Distribui√ß√£o de classes
A vari√°vel alvo `Class` √© uma vari√°vel bin√°ria (composta apenas por 1 e 0) assim√©trica (as classes n√£o est√£o distribu√≠das igualmente), com a classe de fraudes `1` representando uma pequena fra√ß√£o do total (**0,172%**). Ou seja, um modelo treinado com esses dados tenderia a prever sempre a classe majorit√°ria, obtendo alta acur√°cia, mas ignorando as fraudes. Para isso, ser√£o testadas as t√©cnicas `Undersampling`, `Oversampling ` e `SMOTE `.

### Correla√ß√£o entre vari√°veis
Foi testado, primeiramente, a correla√ß√£o de Pearson. Mas, como se tratam de dados n√£o lineares, todas as correla√ß√£o foram baixas. Para isso, foi utilizado MI (Mutual Information) e RF (Random Forest), onde quanto maior o MI, mais a vari√°vel ajuda a reduzir a incerteza sobre a vari√°vel alvo `Class`.
O MI foi normalizado em rela√ß√£o √† entropia da vari√°vel Class (`~0.01834 bits`) para calcular a % de entropia explicada. Ap√≥s isso, foi treinada uma RF para extrair a import√¢ncia atribu√≠da a cada vari√°vel com base na redu√ß√£o de impureza. Para a sele√ß√£o de vari√°veis, foram utilizados os seguintes crit√©rios:
* MI ‚â• 0.005
* % Entropia Explicada ‚â• 20%
* RF Importance ‚â• 0.03

| Vari√°vel | Mutual Information | % Entropia Explicada | Random Forest Importance |
|----------|--------------------|----------------------|---------------------------|
| V14      | 0.008136           | 44.35%               | 0.1772                    |
| V10      | 0.007530           | 41.05%               | 0.1163                    |
| V12      | 0.007601           | 41.44%               | 0.1057                    |
| V17      | 0.008258           | 45.02%               | 0.0888                    |
| V11      | 0.006831           | 37.24%               | 0.0520                    |
| V16      | 0.006144           | 33.50%               | 0.0498                    |

### Lidando com o desbalanceamento
Durante os testes, foram avaliados quatro abordagens para lidar com o desbalanceamento extremo do conjunto de dados (fraudes ‚âà 0,17%):

## Compara√ß√£o de T√©cnicas de Balanceamento

| T√©cnica           |   TP |   FN |    FP |   Precision |   Recall |         F1 |   ROC AUC |   Threshold |
|:------------------|-----:|-----:|------:|------------:|---------:|-----------:|----------:|------------:|
| **Sem Balanceamento** |  119 |   29 |    34 |  0.777778   | 0.804054 | 0.790698   |  0.952014 |        0.41 |
| NearMiss-1        |  144 |    4 | 74666 |  0.00192488 | 0.972973 | 0.00384215 |  0.902703 |        0.5  |
| NearMiss-2        |  128 |   20 | 29475 |  0.00432389 | 0.864865 | 0.00860475 |  0.881739 |        0.5  |
| NearMiss-3        |  118 |   30 |   170 |  0.409722   | 0.797297 | 0.541284   |  0.912913 |        0.5  |
| ADASYN            |  122 |   26 |  2167 |  0.0532984  | 0.824324 | 0.100123   |  0.94517  |        0.5  |
| SMOTE+Tomek       |  119 |   29 |   422 |  0.219963   | 0.804054 | 0.345428   |  0.950103 |        0.5  |
| EasyEnsemble      |  126 |   22 |  3661 |  0.0332717  | 0.851351 | 0.0640407  |  0.943477 |        0.5  |
| BalancedRF        |  130 |   18 |  2618 |  0.0473071  | 0.878378 | 0.089779   |  0.958013 |        0.5  |

Foi conclu√≠do que modelos robustos que conseguem lidar com grande desbalanceamento, igual ao `XGBoost` e `Random Forest`, conseguiram melhores resultados utilizando o conjunto desbalanceado do que com t√©cnicas de balanceamento.

## ü§ñ Escolha do Modelo Final
**Modelos comparados sem reamostragem:**
| Modelo            | Precision  | Recall     | F1 Score   | ROC AUC    |
| ----------------- | ---------- | ---------- | ---------- | ---------- |
| **Random Forest** | **0.9397** | 0.7826     | **0.8537** | 0.9297     |
| **XGBoost**       | 0.7999     | **0.8252** | 0.8122     | **0.9554** |

Foi optado pelo ``Random Forest`` como modelo final, por apresentar o melhor equil√≠brio entre precis√£o e capacidade geral do modelo, especialmente considerando o objetivo de evitar falsos alarmes excessivos.

### Treinando o modelo
O modelo ``Random Forest`` foi treinado com 70% do conjunto de dados e 30% para o teste do modelo. Inicialmente, o modelo foi treinado com threshold de 0.5 e forneceu os seguintes resultados:

```python
features = ['V14', 'V10', 'V12', 'V17', 'V11', 'V16']

X = df[features]
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)

rf_model.fit(X_train, y_train)
```

| Classe       | M√©trica                   | Valor   |
| ------------ | ------------------------- | ------- |
| 0 (leg√≠tima) | TN (corretas)             | 85.290  |
| 0 (leg√≠tima) | FP (barradas por engano)  | **5**  |
| 1 (fraude)   | FN (fraudes que passaram) | **36**  |
| 1 (fraude)   | TP (fraudes detectadas)   | **112** |

Ou seja, o modelo teve um grande resultado em rela√ß√£o a falsos positivos, mas teve um erro de 24% em barrar fraudes leg√≠timas.

Com isso, foram testados novos treinamentos com diferentes thresholds:

**threshold = 0.25**

| Classe       | M√©trica                   | Valor   |
| ------------ | ------------------------- | ------- |
| 0 (leg√≠tima) | TN (corretas)             | 85.277  |
| 0 (leg√≠tima) | FP (barradas por engano)  | **18**  |
| 1 (fraude)   | FN (fraudes que passaram) | **30**  |
| 1 (fraude)   | TP (fraudes detectadas)   | **118** |

**Redu√ß√£o de 16,67% no n√∫mero de fraudes, mas um aumento de 260% nas transa√ß√µes barradas por engano.**

**threshold = 0.20**

| Classe       | M√©trica                   | Valor   |
| ------------ | ------------------------- | ------- |
| 0 (leg√≠tima) | TN (corretas)             | 85.273  |
| 0 (leg√≠tima) | FP (barradas por engano)  | **22**  |
| 1 (fraude)   | FN (fraudes que passaram) | **28**  |
| 1 (fraude)   | TP (fraudes detectadas)   | **120** |

**Redu√ß√£o de 22,22% no n√∫mero de fraudes, mas um aumento de 340% nas transa√ß√µes barradas por engano.**

**threshold = 0.15**

| Classe       | M√©trica                   | Valor   |
| ------------ | ------------------------- | ------- |
| 0 (leg√≠tima) | TN (corretas)             | 85.265  |
| 0 (leg√≠tima) | FP (barradas por engano)  | **30**  |
| 1 (fraude)   | FN (fraudes que passaram) | **27**  |
| 1 (fraude)   | TP (fraudes detectadas)   | **121** |

**Redu√ß√£o de 25% no n√∫mero de fraudes, mas um aumento de 500% nas transa√ß√µes barradas por engano.**

---
**Identificando novas melhorias, foi testado o uso da calibra√ß√£o e fun√ß√µes para identificar a melhor combina√ß√£o de par√¢metros.**

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

def build_optimized_model(X_train, y_train):
    base_rf = RandomForestClassifier(
        class_weight='balanced',
        random_state=42
    )
    
    calibrated = CalibratedClassifierCV(
        base_rf,
        method='isotonic',
        cv=3
    )
    
    param_grid = {
        'base_estimator__n_estimators': [100, 200],
        'base_estimator__max_depth': [5, 10, None],
        'base_estimator__min_samples_leaf': [1, 2],
        'method': ['sigmoid', 'isotonic']
    }
    
    search = GridSearchCV(
        calibrated,
        param_grid,
        scoring='f1',
        cv=3,
        n_jobs=-1,
        verbose=1
    )
    
    search.fit(X_train, y_train)
    return search.best_estimator_

optimized_model = build_optimized_model(X_train, y_train)
y_proba_opt = optimized_model.predict_proba(X_test)[:, 1]
optimal_threshold_opt = find_optimal_threshold(y_test, y_proba_opt)
y_pred_opt = (y_proba_opt >= optimal_threshold_opt).astype(int)
```

**Onde os resultados foram minimamente melhores:**

| Classe       | M√©trica                   | Valor   |
| ------------ | ------------------------- | ------- |
| 0 (leg√≠tima) | TN (corretas)             | 85.252  |
| 0 (leg√≠tima) | FP (barradas por engano)  | **43**  |
| 1 (fraude)   | FN (fraudes que passaram) | **25**  |
| 1 (fraude)   | TP (fraudes detectadas)   | **123** |
