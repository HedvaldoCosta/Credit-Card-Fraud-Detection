# üõ°Ô∏è Detec√ß√£o de Fraude em Cart√µes de Cr√©dito com Machine Learning

Este projeto apresenta uma abordagem de machine learning para identificar transa√ß√µes potencialmente fraudulentas em um grande conjunto de dados de cart√µes de cr√©dito. O objetivo √© desenvolver um modelo eficiente, confi√°vel e interpret√°vel para apoiar decis√µes em ambientes de risco financeiro.

---

## üìÇ Sum√°rio

- [Contexto do Problema](#contexto-do-problema)
- [Objetivos do Projeto](#objetivos-do-projeto)
- [Descri√ß√£o dos Dados](#descri√ß√£o-dos-dados)
- [An√°lise explorat√≥ria de dados](#analise-exploratoria-de-dados)
---

## üìå Contexto do Problema

Fraudes com cart√µes de cr√©dito causam bilh√µes em preju√≠zo √†s institui√ß√µes financeiras anualmente. A maioria dos sistemas de detec√ß√£o tradicionais apresenta dificuldades em:
- Adaptar-se a padr√µes de fraude em constante mudan√ßa
- Lidar com dados extremamente desbalanceados
- Minimizar falsos positivos sem deixar fraudes passarem despercebidas

---

## üéØ Objetivos do Projeto

- Desenvolver um modelo de classifica√ß√£o bin√°ria para prever fraudes em transa√ß√µes de cart√£o de cr√©dito
- Avaliar a performance com m√©tricas adequadas a datasets desbalanceados
- Demonstrar um pipeline completo de machine learning com boas pr√°ticas de engenharia de dados e valida√ß√£o

---

## üßæ Descri√ß√£o dos Dados

- **Fonte**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Tipos de dados**: 30 float64 e 1 int64
- **Total de transa√ß√µes**: 284.807 (sem dados ausentes)
- **Transa√ß√µes fraudulentas**: 492 (aproximadamente 0,172%)
- **Colunas principais**:
  - `V1` a `V28`: vari√°veis transformadas via PCA para anonimiza√ß√£o
  - `Amount`: valor da transa√ß√£o
  - `Time`: segundos desde a primeira transa√ß√£o no dataset
  - `Class`: vari√°vel alvo (0 = leg√≠tima, 1 = fraude)

---
## üìä An√°lise explorat√≥ria de dados

### Distribui√ß√£o de classes
A vari√°vel alvo `Class` √© uma vari√°vel bin√°ria (composta apenas por 1 e 0) assim√©trica (as classes n√£o est√£o distribu√≠das igualmente), com a classe de fraudes `1` representando uma pequena fra√ß√£o do total (**0,172%**). Ou seja, um modelo treinado com esses dados tenderia a prever sempre a classe majorit√°ria, obtendo alta acur√°cia, mas ignorando as fraudes. Para isso, ser√£o testadas as t√©cnicas `Undersampling`, `Oversampling ` e `SMOTE `.

### Correla√ß√£o entre vari√°veis
Foi testado, primeiramente, a correla√ß√£o de Pearson. Mas, como se tratam de dados n√£o lineares, todas as correla√ß√£o foram baixas. Para isso, foi utilizado MI (Mutual Information) e RF (Random Forest), onde quanto maior o MI, mais a vari√°vel ajuda a reduzir a incerteza sobre a vari√°vel alvo `Class`.
O MI foi normalizado em rela√ß√£o √† entropia da vari√°vel Class (`~0.01834 bits`) para calcular a % de entropia explicada. Ap√≥s isso, foi treinada uma RF para extrair a import√¢ncia atribu√≠da a cada vari√°vel com base na redu√ß√£o de impureza. Para a sele√ß√£o de vari√°veis, foram utilizados os seguintes crit√©rios:
* MI ‚â• 0.005
* % Entropia Explicada ‚â• 20%
* RF Importance ‚â• 0.03

| Vari√°vel | Mutual Information | % Entropia Explicada | Random Forest Importance |
|----------|--------------------|----------------------|---------------------------|
| V14      | 0.008136           | 44.35%               | 0.1772                    |
| V10      | 0.007530           | 41.05%               | 0.1163                    |
| V12      | 0.007601           | 41.44%               | 0.1057                    |
| V17      | 0.008258           | 45.02%               | 0.0888                    |
| V11      | 0.006831           | 37.24%               | 0.0520                    |
| V16      | 0.006144           | 33.50%               | 0.0498                    |


