# üõ°Ô∏è Detec√ß√£o de Fraude em Cart√µes de Cr√©dito com Machine Learning

Este projeto apresenta uma abordagem de machine learning para identificar transa√ß√µes potencialmente fraudulentas em um grande conjunto de dados de cart√µes de cr√©dito. O objetivo √© desenvolver um modelo eficiente, confi√°vel e interpret√°vel para apoiar decis√µes em ambientes de risco financeiro.

---

## üìÇ Sum√°rio

- [Contexto do Problema](#contexto-do-problema)
- [Objetivos do Projeto](#objetivos-do-projeto)
- [Descri√ß√£o dos Dados](#descri√ß√£o-dos-dados)
- [An√°lise explorat√≥ria de dados](#analise-exploratoria-de-dados)
---

## üìå Contexto do Problema

Fraudes com cart√µes de cr√©dito causam bilh√µes em preju√≠zo √†s institui√ß√µes financeiras anualmente. A maioria dos sistemas de detec√ß√£o tradicionais apresenta dificuldades em:
- Adaptar-se a padr√µes de fraude em constante mudan√ßa
- Lidar com dados extremamente desbalanceados
- Minimizar falsos positivos sem deixar fraudes passarem despercebidas

---

## üéØ Objetivos do Projeto

- Desenvolver um modelo de classifica√ß√£o bin√°ria para prever fraudes em transa√ß√µes de cart√£o de cr√©dito
- Avaliar a performance com m√©tricas adequadas a datasets desbalanceados
- Demonstrar um pipeline completo de machine learning com boas pr√°ticas de engenharia de dados e valida√ß√£o

---

## üßæ Descri√ß√£o dos Dados

- **Fonte**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Tipos de dados**: 30 float64 e 1 int64
- **Total de transa√ß√µes**: 284.807 (sem dados ausentes)
- **Transa√ß√µes fraudulentas**: 492 (aproximadamente 0,172%)
- **Colunas principais**:
  - `V1` a `V28`: vari√°veis transformadas via PCA para anonimiza√ß√£o
  - `Amount`: valor da transa√ß√£o
  - `Time`: segundos desde a primeira transa√ß√£o no dataset
  - `Class`: vari√°vel alvo (0 = leg√≠tima, 1 = fraude)

---
## üìä An√°lise explorat√≥ria de dados

### Distribui√ß√£o de classes
A vari√°vel alvo `Class` √© uma vari√°vel bin√°ria (composta apenas por 1 e 0) assim√©trica (as classes n√£o est√£o distribu√≠das igualmente), com a classe de fraudes `1` representando uma pequena fra√ß√£o do total (**0,172%**). Ou seja, um modelo treinado com esses dados tenderia a prever sempre a classe majorit√°ria, obtendo alta acur√°cia, mas ignorando as fraudes. Para isso, ser√£o testadas as t√©cnicas `Undersampling`, `Oversampling ` e `SMOTE `.

### Correla√ß√£o entre vari√°veis
Foi testado, primeiramente, a correla√ß√£o de Pearson. Mas, como se tratam de dados n√£o lineares, todas as correla√ß√£o foram baixas. Para isso, foi utilizado MI (Mutual Information) e RF (Random Forest), onde quanto maior o MI, mais a vari√°vel ajuda a reduzir a incerteza sobre a vari√°vel alvo `Class`.
O MI foi normalizado em rela√ß√£o √† entropia da vari√°vel Class (`~0.01834 bits`) para calcular a % de entropia explicada. Ap√≥s isso, foi treinada uma RF para extrair a import√¢ncia atribu√≠da a cada vari√°vel com base na redu√ß√£o de impureza. Para a sele√ß√£o de vari√°veis, foram utilizados os seguintes crit√©rios:
* MI ‚â• 0.005
* % Entropia Explicada ‚â• 20%
* RF Importance ‚â• 0.03

| Vari√°vel | Mutual Information | % Entropia Explicada | Random Forest Importance |
|----------|--------------------|----------------------|---------------------------|
| V14      | 0.008136           | 44.35%               | 0.1772                    |
| V10      | 0.007530           | 41.05%               | 0.1163                    |
| V12      | 0.007601           | 41.44%               | 0.1057                    |
| V17      | 0.008258           | 45.02%               | 0.0888                    |
| V11      | 0.006831           | 37.24%               | 0.0520                    |
| V16      | 0.006144           | 33.50%               | 0.0498                    |

### Lidando com o desbalanceamento
Durante os testes, foram avaliados quatro abordagens para lidar com o desbalanceamento extremo do conjunto de dados (fraudes ‚âà 0,17%):
| Estrat√©gia           | Precision  | Recall     | F1 Score   | ROC AUC    |
| -------------------- | ---------- | ---------- | ---------- | ---------- |
| **Undersampling**    | 0.7612     | 0.7951     | 0.7765     | 0.9211     |
| **Oversampling**     | 0.7713     | 0.7903     | 0.7807     | 0.9230     |
| **SMOTE**            | 0.7899     | 0.8020     | 0.7959     | 0.9270     |
| **Sem reamostragem** | **0.7999** | **0.8252** | **0.8122** | **0.9554** |

Foi conclu√≠do que modelos robustos que conseguem lidar com grande desbalanceamento, igual ao `XGBoost` e `Random Forest`, conseguiram melhores resultados utilizando o conjunto desbalanceado do que com t√©cnicas de desbalanceamento igual `SMOTE`. 

## ü§ñ Escolha do Modelo Final
**Modelos comparados sem reamostragem:**
| Modelo            | Precision  | Recall     | F1 Score   | ROC AUC    |
| ----------------- | ---------- | ---------- | ---------- | ---------- |
| **Random Forest** | **0.9397** | 0.7826     | **0.8537** | 0.9297     |
| **XGBoost**       | 0.7999     | **0.8252** | 0.8122     | **0.9554** |

Foi optado pelo ``Random Forest`` como modelo final, por apresentar o melhor equil√≠brio entre precis√£o e capacidade geral do modelo, especialmente considerando o objetivo de evitar falsos alarmes excessivos.

### Treinando o modelo
O modelo ``Random Forest`` foi treinado com 70% do conjunto de dados e 30% para o teste do modelo. Inicialmente, o modelo foi treinado com threshold de 0.5 e forneceu os seguintes resultados:

| Decis√£o            | N√£o fraude  | Fraude     
| ----------------- | ---------- | ---------- | 
| Passou | 85.290 | 36     |
| N√£o passou       | 5     | 112 |

Ou seja, o modelo teve um grande resultado em rela√ß√£o a falsos positivos, mas teve um erro de 24% em barrar fraudes leg√≠timas.